{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada una colección de documentos queremos encontrar\n",
    "frases de 1 , 2 o 3 palabras que sean anagramas de otras. Por\n",
    "ejemplo: (“Postmaster”, “Stamp store”) o (“A telescope” , “To\n",
    "see Place”) o (“The cockroach”, “cook catch her”). Esta tarea\n",
    "implica una combinatoria muy difícil por lo que se decide usar\n",
    "Map-Reduce para paralelizarla. Usando Map-Reduce programar\n",
    "la solución a este problema listando todos los pares de\n",
    "anagramas entre frases de 1, 2 o 3 palabras. Como puede\n",
    "verse en los ejemplos se ignoran mayúsculas y minúsculas y\n",
    "los espacios en blanco, puntuación, etc. Suponer que existe la\n",
    "función word_tokenizer que recibe un texto y devuelve un\n",
    "vector de palabras ya convertidas a minúsculas y sin\n",
    "puntuación.\n",
    "\n",
    "[Link](https://piazza-resources.s3.amazonaws.com/i66tbiovo343uu/i9aqver262d79x/2015_1c_Parcial_1.pdf?AWSAccessKeyId=AKIAIEDNRLJ4AZKBW6HA&Expires=1502774983&Signature=gUHN0w4gL2uLGlpvKr0Lxf0RKDQ%3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el paquete de wikipedia obtendremos el texto de un articulo para tener de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wp\n",
    "wp.set_lang('en')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = set(list(string.ascii_lowercase) + list(string.ascii_uppercase)\\\n",
    "    +list(string.digits) + [' ','.','-','\\n'])\n",
    "sampleText = ''.join(x for x in wp.page(\"Alan turing\").content if x in letters).replace('\\n','.').split('.')\n",
    "rdd = sc.parallelize(sampleText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso usaremos cada oracion del articulo como un documento. Para encontrar los anagramas pondremos todos los documentos en lowercase de modo que por ejemplo \"Alter the\" y \"the later\" sean anagramas. Tambien eliminaremos las frases que han quedado vacias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda y: y.lower()).filter(lambda x: len(x)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir una funcion que nos obtiene los n-gramas de n palabras de cada elemento de un rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams(element,n):\n",
    "    lis = []\n",
    "    splitted = element.split()\n",
    "    for ind in xrange(0,len(splitted)-n):\n",
    "        lis.append(' '.join(splitted[ind:ind+n]))\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los n-gramas para n 1,2,3 y unimos todo. Luego de esto, tenemos una lista de listas de n-gramas, aplicamos flatmap para obtener una sola lista con los elementos de cada una de las tres listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd1 = rdd.map(lambda x: split2(x,1))\n",
    "rdd2 = rdd.map(lambda x: split2(x,2))\n",
    "rdd3 = rdd.map(lambda x: split2(x,3))\n",
    "rddf = rdd1.union(rdd2.union(rdd3)).flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enunciado nos pide encontrar los pares de anagramas en este rdd. Eso implica que tendran las mismas letras, los espacios no importan. Entonces uniremos los n elementos de cada uno de los n-gramas, eliminando los espacios y ordenando el string (podrian armarse sets de este mismo modo). Con esto armamos una tupla de (elemento ordenado,elemento). Agrupando segun la clave (el primer elemento de la tupla == el elemento ordenado) tenemos una lista de todos los anagramas por clave. Claramente debemos filtrar aquellos que hayan aparecido solo una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'onto', u'on to'],\n",
       " [u'crime to the', u'the crime to'],\n",
       " [u'designer of the', u'the designer of'],\n",
       " [u'a road and', u'road and a'],\n",
       " [u'the committee', u'committee the'],\n",
       " [u'the idea of', u'of the idea'],\n",
       " [u'ics brought the', u'the ics brought'],\n",
       " [u'it has', u'at his'],\n",
       " [u'1949', u'1994'],\n",
       " [u'form of the', u'the form of'],\n",
       " [u'a model of', u'model of a'],\n",
       " [u'good a', u'a good'],\n",
       " [u'their importance and', u'importance and their'],\n",
       " [u'origins of the', u'the origins of'],\n",
       " [u'pardon to', u'to pardon'],\n",
       " [u'later', u'alter'],\n",
       " [u'for one', u'one for'],\n",
       " [u'cats', u'acts', u'cast'],\n",
       " [u'bletchley park the', u'the bletchley park'],\n",
       " [u'turing as', u'as turing']]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddf = rddf.map(lambda x: (''.join(sorted(x.replace(' ',''))),x))\n",
    "rddf = rddf.groupByKey().map(lambda x: list(set(x[1]))).filter(lambda x: len(x)>1)\n",
    "rddf.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el output de la celda anterior podemos ver lo siguiente: casi todos los \"anagramas\" de multiples palabras son en realidad las mismas palabras ordenadas de distinto modo. Procedemos a arreglar esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'onto', u'on to'],\n",
       " [u'it has', u'at his'],\n",
       " [u'1949', u'1994'],\n",
       " [u'later', u'alter'],\n",
       " [u'cats', u'acts', u'cast'],\n",
       " [u'the acm', u'the cam'],\n",
       " [u'does', u'dose'],\n",
       " [u'he turned', u'under the'],\n",
       " [u'own', u'now', u'won'],\n",
       " [u'had set', u'deaths'],\n",
       " [u'setting', u'testing'],\n",
       " [u'a set', u'east'],\n",
       " [u'reversed', u'reserved'],\n",
       " [u'ronald', u'arnold'],\n",
       " [u'1938', u'1983'],\n",
       " [u'that is', u'at this'],\n",
       " [u'computersthe manchester', u'the manchester computers'],\n",
       " [u'1022', u'2012'],\n",
       " [u'codebreaking', u'code breaking'],\n",
       " [u'sidney', u'disney'],\n",
       " [u'report', u'porter'],\n",
       " [u'that now', u'than two'],\n",
       " [u'are a', u'area'],\n",
       " [u'nsa', u'san'],\n",
       " [u'on', u'no'],\n",
       " [u'so on', u'soon'],\n",
       " [u'cautioned', u'education'],\n",
       " [u'from', u'form'],\n",
       " [u'little', u'tell it'],\n",
       " [u'how alan turing', u'alan turing who'],\n",
       " [u'tons a', u'not as'],\n",
       " [u'was ethel', u'wales the'],\n",
       " [u'role of dna', u'and role of'],\n",
       " [u'not know', u'known to'],\n",
       " [u'how', u'who'],\n",
       " [u'dies', u'side'],\n",
       " [u'there', u'three'],\n",
       " [u'alter the', u'the later', u'later the'],\n",
       " [u'in 1928', u'in 1982'],\n",
       " [u'ear', u'are'],\n",
       " [u'was on', u'was no'],\n",
       " [u'smile', u'miles'],\n",
       " [u'1928', u'1982'],\n",
       " [u'1954', u'1945'],\n",
       " [u'a paper', u'appear'],\n",
       " [u'sure', u'user'],\n",
       " [u'indeed', u'denied'],\n",
       " [u'2001', u'2010'],\n",
       " [u'large', u'regal'],\n",
       " [u'2001 in', u'in 2010'],\n",
       " [u'asa', u'as a'],\n",
       " [u'outside', u'i used to'],\n",
       " [u'design', u'signed'],\n",
       " [u'morten', u'mentor'],\n",
       " [u'aim', u'i am'],\n",
       " [u'into', u'it on'],\n",
       " [u'and was', u'dna was'],\n",
       " [u'directed', u'credited'],\n",
       " [u'wrote a', u'two are'],\n",
       " [u'and', u'dna'],\n",
       " [u'in wales', u'lewin as'],\n",
       " [u'broad', u'board'],\n",
       " [u'dies the', u'the side'],\n",
       " [u'on 13', u'on 31'],\n",
       " [u'then we', u'he went'],\n",
       " [u'letterthis', u'this letter'],\n",
       " [u'for them', u'the form', u'from the'],\n",
       " [u'31 march', u'13 march'],\n",
       " [u'late', u'tale', u'et la'],\n",
       " [u'same', u'me as'],\n",
       " [u'13', u'31'],\n",
       " [u'in 1994', u'in 1949'],\n",
       " [u'later to', u'to alter'],\n",
       " [u'with an', u'in what'],\n",
       " [u'12', u'21'],\n",
       " [u'on 12', u'on 21'],\n",
       " [u'the war he', u'whether a'],\n",
       " [u'but as', u'a bust'],\n",
       " [u'named a', u'made an'],\n",
       " [u'game in', u'enigma'],\n",
       " [u'things as', u'hastings'],\n",
       " [u'thing', u'night'],\n",
       " [u'felt', u'left'],\n",
       " [u'another', u'heart on'],\n",
       " [u'acm', u'cam'],\n",
       " [u'the more', u'theorem'],\n",
       " [u'a winston', u'was not in'],\n",
       " [u'in so', u'is no'],\n",
       " [u'the year', u'they are'],\n",
       " [u'diverse', u'revised'],\n",
       " [u'on 13 march', u'on 31 march']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def uniqueWords(ngrams):\n",
    "    r = []\n",
    "    l = []\n",
    "    for i in ngrams:\n",
    "        iset = set(i.split())\n",
    "        if set.difference(*(r+[iset])) != set([]):\n",
    "            r.append(iset)\n",
    "            l.append(i)\n",
    "    return l\n",
    "    \n",
    "rddf = rddf.map(lambda x: uniqueWords(x)).filter(lambda x: len(x)>1)\n",
    "rddf.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
