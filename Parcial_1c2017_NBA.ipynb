{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSIGNA\n",
    "\n",
    "Se  tiene  información  estadística  de  la  temporada  regular  de  todos  los jugadores   de   la   NBA   en   un   RDD   de   tuplas   con   el   siguiente   formato:\n",
    "\n",
    "<span style=\"color:darkred\"><em>\n",
    "(id_jugador, nombre, promedio_puntos, promedio_asistencias, promedio_robos, promedio_bloqueos,  promedio_rebotes,  promedio_faltas). \n",
    "</em></span> \n",
    "\n",
    "Un  analista  de  la cadena ESPN  está  trabajando  con  un  RDD que corresponde  a  la primera  ronda  de playoffs y que tiene el siguiente formato: \n",
    "\n",
    "<span style=\"color:darkred\"><em>\n",
    "(id_jugador, id_partido, timestamp, cantidad_puntos, cantidad_rebotes, cantidad_bloqueos, cantidad_robos, cantidad_asistencias,   cantidad_faltas).\n",
    "</em></span>\n",
    "  \n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "En   base   a estos   RDDs   se   quiere  programar  en  PySpark  un  programa  que  genere  un  RDD  con  los  nombres  (sin duplicados)  de  los  jugadores  que  lograron  en  algún  partido  de  playoffs  una  cantidad de asistencias mayor a su promedio histórico (el de la temporada regular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamaremos:\n",
    "\n",
    "rdd_po: RDD con los datos de los playoffs. <br />\n",
    "rdd_tr: RDD con los datos de temporada regular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Por si hay mas de un contexto de PySpark corriendo (por ejemplo, otro Notebook), esto para utilizar el mismo.\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dejo al RDD de playoffs solo con tuplas de formato ((id_jugador, id_partido), cantidad_asistencias) \n",
    "rdd_po = rdd_po.map(lambda x: ( (x[0],x[1]), x[7] ))\n",
    "\n",
    "#Dejo al RDD de temporadas regulares solo con tuplas de formato (id_jugador, [nombre, promedio_asistencias]) \n",
    "rdd_tr = rdd_tr.map(lambda x: ( x[0], [x[1], x[3]] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# En este paso, se toma el RDD de playoffs.\n",
    "# Primero, se agrupan y suman todos los asistencias que corresponden a un mismo jugador en un mismo partido \n",
    "# (ya que un jugador pudo haber salido y vuelto a entrar, por ejemplo).\n",
    "#\n",
    "# Inmediatamente despues, convertimos todos esos registros en tuplas de formato: \n",
    "# (id_jugador, cantidad_asistencias_total_en_partido)\n",
    "\n",
    "rdd_po = rdd_po.reduceByKey(lambda x,y: x+y).map(lambda x: (x[0][0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ahora, nos quedamos con el maximo de asistencias de cada jugador en un partido de playoffs (si el maximo no\n",
    "# supera el promedio, entonces ese jugador no cumple).\n",
    "#\n",
    "# Luego, se toma eso y se convierte en tuplas de formato \n",
    "# (id_jugador, [cantidad_asistencias_maximo])\n",
    "\n",
    "rdd_po = rdd_po.reduceByKey(lambda x,y: max(x,y)).map(lambda x: (x[0], [x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Joineamos por id_jugador ambos RDD, por lo que nos quedarian tuplas de formato:\n",
    "# (id_jugador, ([cantidad_asistencias_maximo], [nombre, promedio_asistencias]))\n",
    "#\n",
    "# Pasa a convertir el segundo elemento de cada registro en una unica lista concatenada de forma:\n",
    "# [cantidad_asistencias_maximo, nombre, promedio_asistencias]\n",
    "\n",
    "rdd_combinado = rdd_po.join(rdd_tr).map(lambda x: (x[0], x[1][0] + x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A lo ultimo, filtramos y nos quedamos solo con aquellos que su cantidad_asistencias_maximo es mayor a su\n",
    "# promedio_asistencias.\n",
    "# Paso siguiente, de aquellos jugadores que cumplieron con lo buscado, nos quedamos solo con su nombre.\n",
    "# Devolvemos la lista de nombres de jugadores que superaron su promedio de asistencias en algun partido de playoffs.\n",
    "\n",
    "rdd_combinado = rdd_combinado.filter(lambda x: x[1][0] > x[1][2]).map(lambda x: x[1][1])\n",
    "rdd_combinado.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
