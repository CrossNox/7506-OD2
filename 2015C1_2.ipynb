{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una colección de documentos (textos) y se quiere\n",
    "calcular el promedio de la cantidad de caracteres que tienen\n",
    "las frases de 2,3 y 4 palabras en toda la colección. Programar\n",
    "la solución a este problema usando Map-Reduce usando\n",
    "combiners como método de agregación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a definir una funcion que dado un documento devuelva una lista de frases de 2, 3 y 4 palabras. Luego mapearla a un RDD con un par de documentos de wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frases(documento):\n",
    "    frases = []\n",
    "    for frase in documento.replace('\\n',' ').split(\".\"):\n",
    "        palabras = frase.split(\" \")\n",
    "        for i in range(len(palabras)+1):\n",
    "            if i>=2: frases.append((\" \".join(palabras[i-2:i]),2))\n",
    "            if i>=3: frases.append((\" \".join(palabras[i-3:i]),3))\n",
    "            if i>=4: frases.append((\" \".join(palabras[i-4:i]),4))\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wp\n",
    "wp.set_lang(\"en\")\n",
    "articulo1 = wp.page(\"Paul Gilbert\").summary\n",
    "articulo2 = wp.page(\"Chris Impellitteri\").summary\n",
    "articulo3 = wp.page(\"Steve Vai\").summary\n",
    "articulo4 = wp.page(\"Eddie Van Halen\").summary\n",
    "rdd = sc.parallelize([articulo1,articulo2,articulo3,articulo4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un RDD donde cada registro es el resumen de una pagina de wikipedia. Mapeamos get_frases a cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(get_frases).flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos un RDD donde cada registro es una lista de tuplas de la forma `<palabras, cantidad de palabras>`. La idea seria agrupar por cantidad de palabras en la frase. Para conocer el promedio de caracteres, necesitamos la cantidad de frases y la suma de sus largos. Entonces necesitamos sumar los largos y 1 por cada palabra. \n",
    "Acomodamos la cantidad de palabras en la frase como clave y hacemos `reduceByKey` para sumar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda x: (x[1], (len(x[0]), 1)))\n",
    "rdd = rdd.reduceByKey(lambda x, y: (x[0]+y[0],x[1]+y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la cantidad de frases y la suma de caracteres, hacemos map sobre los valores con `mapValues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.mapValues(lambda x: round(float(x[0])/x[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 10.71), (3, 16.72), (4, 22.79)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
