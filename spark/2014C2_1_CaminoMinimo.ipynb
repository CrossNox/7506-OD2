{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene un grafo dirigido representado mediante una lista\n",
    "de adyacencias. Dado un nodo inicial y un nodo final queremos\n",
    "que programe usando Map-Reduce un algoritmo que indique\n",
    "cuál es el camino mínimo entre ambos nodos. En clase vimos\n",
    "como calcular la longitud, ahora queremos saber cuál es el\n",
    "camino.\n",
    "\n",
    "[Link](https://piazza.com/class_profile/get_resource/jkr2voxi1yw4wt/jkr2vqsaag24y5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteo del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a presentar primero el caso general de grafos dirigidos con pesos, utilizando el algoritmo de Ford-Bellman distribuido. Luego, voy a mostrar las modificaciones necesarias para tratar con el problema de grafos dirigidos no pesados sencillamente tomando 1 como peso para todas las aristas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "\n",
    "def draw(G):\n",
    "    return Image(G.draw(format='png', prog='dot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camino minimo con Spark para grafos dirigidos pesados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un grafo con listas de adyacencias, con pesos aleatorios entre 1 y 15. Lo grafico con (pygraphviz)[http://pygraphviz.github.io/documentation/pygraphviz-1.4rc1/install.html#quick-install] para poder validar manualmente los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [('a', [('b', 7)]), \n",
    "         ('b', [('c', 8), ('d', 3), ('f', 10)]), \n",
    "         ('c', [('e', 6), ('h', 7), ('a', 13)]), \n",
    "         ('d', [('g', 13)]), \n",
    "         ('e', [('d', 8), ('k', 14)]), \n",
    "         ('f', [('b', 2), ('d', 10)]), \n",
    "         ('g', [('i', 7)]), \n",
    "         ('h', []), \n",
    "         ('i', [('d', 13)]), \n",
    "         ('j', [('e', 2)]), \n",
    "         ('k', [('j', 2)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pgv.AGraph(directed=True)\n",
    "for edge in edges:\n",
    "    G.add_node(edge[0])\n",
    "    for end in edge[1]:\n",
    "        G.add_edge(edge[0],end[0],weight=end[1],label=str(end[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar Map-Reduce no podemos hacer early-stopping si ya llegamos al destino, ya que para ello deberíamos hacer `.collect` del RDD en cada iteración. Esto es una mala práctica, ya que el collect es una operación cara, lenta y que necesita mucho tráfico de datos de los workers al driver. \n",
    "\n",
    "Si tenemos un grafo $G = (V,E)$, entonces necesitamos a lo sumo $|V|-1$ iteraciones, ya que ningún camino será mas largo que ese valor. Entonces hay que hacer $|V|-1$ iteraciones de Map-Reduce.\n",
    "\n",
    "Empezamos con un RDD con un registro por cada vértice, con el siguiente formato:\n",
    "`(start, weight_total, adj_list, path)`\n",
    "* **start** un vértice \n",
    "* **weight_total** el costo de llegar a ese vértice en esa iteración\n",
    "* **adj_list** lista de adyacencias para ese vértice\n",
    "\n",
    "Inicializamos todos los registros con $weight\\_total = \\infty$ excepto por $start$, con peso $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la etapa de `map`, para cada registro en el RDD crearemos una lista con:\n",
    "* el registro original\n",
    "* una lista de nuevos registros donde `start` es un elemento de `adj_list`, `weight_total` es la suma del peso de ir a ese elemento desde el elemento del registro original y `weight_total` hasta el momento y `adj_list` está vacía\n",
    "Luego de explicar la etapa de `reduce` quedará claro por qué `adj_list` se crea vacía para esos últimos registros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la etapa de `reduce` lo que hacemos es simplemente seleccionar el menor valor para `weight` de los dos nodos que recibimos. `adj_list` debe ser la lista original para ese nodo. En la etapa de `map` cuando procesamos ese nodo devolvemos la lista original, todos los demás que devolvemos tienen una lista vacía, asi que básicamente sumamos todas las listas vacías y la lista original. `path` será el valor para `path` del nodo con el valor mas pequeño para `weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamos toda esa lógica dentro de una función que recibe una lista de listas de adyacencias, el vértice inicial y el final y devuelve un string con el camino y el costo.\n",
    "\n",
    "Con la lógica explicada previamente en realidad obtenemos el camino minimo del vértice inicial a todos los demas, pero como solo nos interesa el vértice final, con `filter` obtenemos solo ese registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(edges,start,end):\n",
    "    def map_(node):\n",
    "        lista_nuevos = [node]\n",
    "        lista_nuevos.extend([(x[0],(node[1][0]+x[1],[],node[1][2]+[x[0]])) for x in node[1][1]])\n",
    "        return lista_nuevos\n",
    "\n",
    "    def reduce_(n1,n2):\n",
    "        weight = n1[0] if n1[0] < n2[0] else n2[0]\n",
    "        adj = n1[1]+n2[1]\n",
    "        path = n1[2] if n1[0] < n2[0] else n2[2]\n",
    "        return (weight,adj,path)\n",
    "    \n",
    "    sc.broadcast(end)\n",
    "    rdd = sc.parallelize([(edgelist[0],(0 if edgelist[0]==start else np.inf,edgelist[1],[edgelist[0]])) for edgelist in edges],8)\n",
    "    #start, weight_total, adj_list, path\n",
    "    for _ in range(len(edges)-1):\n",
    "        rdd = rdd.flatMap(map_).reduceByKey(reduce_)\n",
    "    rdd = rdd.filter(lambda x: x[0]==end)\n",
    "    tup = rdd.collect()[0]\n",
    "    return \"No hay camino\" if tup[1][2][0] != start else \"{} (cost {})\".format(\" => \".join(tup[1][2]),tup[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path(edges,'a','h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path(edges,'d','e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camino minimo con Spark para grafos dirigidos no pesados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a usar el mismo grafo, pero esta vez, sin pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = [('a',['b']),('b',['c','d','f']),\\\n",
    "      ('c',['e','h','a']),('d',['g']),\\\n",
    "      ('e',['d','k']),('f',['b','d']),('g',['i']),\\\n",
    "      ('h',[]),('i',['d']),('j',['e']),('k',['j'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pgv.AGraph(directed=True)\n",
    "for edge in adj:\n",
    "    G.add_node(edge[0])\n",
    "    for end in edge[1]:\n",
    "        G.add_edge(edge[0],end[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las única modificacion necesaria para que el algoritmo trabaje con grafos no pesados es \"hardcodear\" un 1 como peso a sumar en la etapa de `map` (para no agregarlo a cada arista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(edges,start,end):\n",
    "    def map_(node):\n",
    "        lista_nuevos = [node]\n",
    "        lista_nuevos.extend([(x[0],(node[1][0]+1,[],node[1][2]+[x[0]])) for x in node[1][1]])\n",
    "        return lista_nuevos\n",
    "\n",
    "    def reduce_(n1,n2):\n",
    "        weight = n1[0] if n1[0] < n2[0] else n2[0]\n",
    "        adj = n1[1]+n2[1]\n",
    "        path = n1[2] if n1[0] < n2[0] else n2[2]\n",
    "        return (weight,adj,path)\n",
    "    \n",
    "    sc.broadcast(end)\n",
    "    rdd = sc.parallelize([(edgelist[0],(0 if edgelist[0]==start else np.inf,edgelist[1],[edgelist[0]])) for edgelist in edges],8)\n",
    "    #start, weight_total, adj_list, path\n",
    "    for _ in range(len(edges)-1):\n",
    "        rdd = rdd.flatMap(map_).reduceByKey(reduce_)\n",
    "    rdd = rdd.filter(lambda x: x[0]==end)\n",
    "    tup = rdd.collect()[0]\n",
    "    return \"No hay camino\" if tup[1][2][0] != start else \"{}\".format(\" => \".join(tup[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path(edges,'g','d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path(edges,'g','f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
