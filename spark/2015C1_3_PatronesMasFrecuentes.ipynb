{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una colección de documentos (textos) almacenados en un\n",
    "cluster. Se quiere establecer un ranking de los patrones mas frecuentes\n",
    "para la aparición de letras en las palabras. Por ejemplo “sister”,\n",
    "“ejects” , “ninety” y “amazon” responden al patrón “abacde”.\n",
    "Programar en map-reduce un programa que genere como resultado un\n",
    "listado de tipo (patron, frecuencia) indicando cuántas veces aparece\n",
    "cada patrón en la colección de documentos. Usar combiners como\n",
    "método de agregación.\n",
    "\n",
    "[Link](https://piazza.com/class_profile/get_resource/jkr2voxi1yw4wt/jkr2vqss6zt4ym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un rdd con el tres documentos obtenidos de wikipedia. Primero mapeo la funcion `word_tokenizer` que crea una lista de palabras desde un string. Como queremos una lista de palabras, hay que usar `flatMap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wp\n",
    "from string import punctuation\n",
    "from re import sub\n",
    "wp.set_lang(\"en\")\n",
    "articulo1 = wp.page(\"Zimbawe\").summary\n",
    "articulo2 = wp.page(\"Camboya\").summary\n",
    "articulo3 = wp.page(\"Djibouti\").summary\n",
    "rdd = sc.parallelize([articulo1,articulo2,articulo3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern(word):\n",
    "    set_letras = {}\n",
    "    pattern = []\n",
    "    for i in word:\n",
    "        if i not in set_letras:\n",
    "            set_letras[i] = len(set_letras)\n",
    "        pattern.append(set_letras[i])\n",
    "    return (tuple(pattern),word)\n",
    "\n",
    "def word_tokenizer(string):\n",
    "    return sub('['+punctuation+']',' ',string.replace('\\n',' ')).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(word_tokenizer).flatMap(lambda x: x)\n",
    "rdd = rdd.filter(lambda x: len(x)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente definimos la funcion `pattern` que devuelve una tupla con una secuencia numerica indicando el patron de la palabra y la palabra. La mapeamos al RDD, agrupamos por patron (clave). Eso nos deja un RDD con registros del tipo `<patron, iterable de palabras>`. Queremos la cantidad de palabras por patron, asi que con `len` obtenemos la cantidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdd = rdd.map(pattern)\n",
    "rdd = rdd.groupByKey()\n",
    "rdd = rdd.mapValues(lambda x: len(x))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma podria haber sido usando `reduceByKey` para sumar, algo asi:  \n",
    "```\n",
    "rdd = rdd.map(pattern)\n",
    "rdd = rdd.map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y)\n",
    "rdd.collect()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
